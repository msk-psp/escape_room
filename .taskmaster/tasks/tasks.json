{
  "master": {
    "tasks": [
      {
        "id": 11,
        "title": "Project Initialization and Database Schema Setup",
        "description": "Establish the foundational database schema in PostgreSQL and set up the initial project structures for both the Python FastAPI backend and the React (with Bun) frontend.",
        "details": "Database: Use PostgreSQL. Create `cafes`, `themes`, `reviews`, and `users` tables as specified in the PRD. The `cafes` table should include `latitude` and `longitude` columns for PostGIS. Backend: Set up a new FastAPI project, configure database connection using SQLAlchemy or a similar ORM, and create initial directories for routers, models, and services. Frontend: Initialize a new React project using Bun, setting up a basic component structure (e.g., `components`, `pages`, `services`).",
        "testStrategy": "Verify that the database schema is created correctly in PostgreSQL. Confirm that both FastAPI and React projects run successfully with their default boilerplate. Write initial model validation tests for the database schema.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup PostgreSQL Database and Define Schema with PostGIS",
            "description": "Provision a PostgreSQL database instance and create the initial schema. This includes enabling the PostGIS extension and defining the `users`, `cafes`, `themes`, and `reviews` tables with their respective columns and relationships.",
            "dependencies": [],
            "details": "Write a `schema.sql` file or use a database migration tool like Alembic to define the table structures. Ensure the PostGIS extension is enabled using `CREATE EXTENSION postgis;`. The `cafes` table must include `latitude` and `longitude` columns, preferably using a PostGIS `GEOGRAPHY(Point, 4326)` type for geospatial queries. Define primary keys, foreign keys, and appropriate data types for all columns as specified in the PRD.",
            "status": "done",
            "testStrategy": "Connect to the database using a client like `psql` or DBeaver and verify that all tables, columns, and constraints exist as defined. Confirm the PostGIS extension is enabled by running `SELECT postgis_version();`."
          },
          {
            "id": 2,
            "title": "Initialize FastAPI Backend Project and Directory Structure",
            "description": "Create a new Python project for the backend using FastAPI. Set up the basic directory structure to organize the application logically for routers, models, services, and configuration.",
            "dependencies": [],
            "details": "Use a dependency manager like Poetry or a `requirements.txt` file to manage Python packages. Install `fastapi`, `uvicorn`, `sqlalchemy`, and `psycopg2-binary`. Create a main application file (`main.py`) and establish a directory structure: `/app`, `/app/api` (for routers), `/app/models`, `/app/services`, `/app/core` (for configuration). Implement a root health check endpoint (`/`) that returns a simple JSON response to confirm the server is running.",
            "status": "done",
            "testStrategy": "Run the application using `uvicorn main:app --reload`. Access `http://127.0.0.1:8000` in a browser or with `curl` to ensure the health check endpoint returns a successful response. Check that the auto-generated OpenAPI docs are available at `/docs`."
          },
          {
            "id": 3,
            "title": "Implement SQLAlchemy Models and Configure Database Connection",
            "description": "Create the SQLAlchemy ORM models corresponding to the PostgreSQL schema and configure the FastAPI application to connect to the database using environment variables.",
            "dependencies": [],
            "details": "In the `/app/models` directory, create Python classes for `User`, `Cafe`, `Theme`, and `Review` that inherit from SQLAlchemy's declarative base. Map these classes to the database tables created in subtask 12. In `/app/core/config.py`, manage the database connection URL using Pydantic's `BaseSettings` to load from environment variables. Create a reusable database session dependency (`get_db`) to be injected into API routes.",
            "status": "done",
            "testStrategy": "Create a temporary test script or an internal API endpoint that uses the `get_db` dependency to establish a session and perform a simple query (e.g., `SELECT 1` or count rows in a table). This will verify that the database connection string, credentials, and ORM models are configured correctly."
          },
          {
            "id": 4,
            "title": "Initialize React Frontend Project with Bun and Basic Structure",
            "description": "Use the Bun toolkit to scaffold a new React application. Set up the initial folder structure for components, pages, and services, and configure basic routing.",
            "dependencies": [],
            "details": "Run `bun create react ./frontend` to initialize the project. Inside the `src` directory, create a standard folder structure: `src/components` (for reusable UI elements), `src/pages` (for top-level route components), `src/services` (for API call logic), and `src/assets`. Install `react-router-dom` and set up a basic router with at least two placeholder pages (e.g., `HomePage`, `MapPage`) to ensure navigation works.",
            "status": "done",
            "testStrategy": "Run `bun dev` in the frontend directory. Verify that the default React application loads correctly in the browser. Navigate between the created placeholder pages to confirm that `react-router-dom` is configured and working as expected."
          },
          {
            "id": 5,
            "title": "Containerize Services with Docker for Development",
            "description": "Create Dockerfiles for the FastAPI backend and a `docker-compose.yml` file to orchestrate the backend, frontend dev server, and PostgreSQL database services for a consistent development environment.",
            "dependencies": [],
            "details": "Create a `Dockerfile` in the backend's root directory to containerize the FastAPI application. In the project root, create a `docker-compose.yml` file. Define three services: `db` (using the `postgis/postgis` image and a volume for data persistence), `backend` (building from its Dockerfile), and `frontend` (using an `oven/bun` image to run the `bun dev` command). Use volumes for both backend and frontend to enable hot-reloading on code changes. Configure environment variables for inter-service communication (e.g., the backend's database URL).",
            "status": "done",
            "testStrategy": "Run `docker-compose up --build` from the project root. Verify that all three containers start without errors by checking the logs with `docker-compose logs`. Confirm the backend can connect to the database container and that the frontend is accessible in the browser. Make a small code change in a backend file and a frontend file to ensure hot-reloading is functional for both services."
          }
        ]
      },
      {
        "id": 12,
        "title": "Data Scraping Engine for Cafe and Theme Information",
        "description": "Refine and automate the existing Selenium-based scraping script (`scraping.py`) to periodically collect escape room cafe and theme information from Naver Maps and official cafe websites.",
        "status": "done",
        "dependencies": [
          11
        ],
        "priority": "high",
        "details": "The project will pivot from a Scrapy-based implementation to enhancing the existing Selenium script (`scraping.py`). The core tasks involve refining the `scrape_naver_map_cafes` function to extract cafe names, addresses, and website URLs. A new function will be developed to scrape theme details (name, genre, difficulty) from the collected official websites. A robust data pipeline will be implemented to clean, deduplicate, and store both cafe and theme data in the PostgreSQL database, ensuring themes are correctly linked to their parent cafes. The entire process will be automated to run weekly using `APScheduler` configured in a `scheduler.py` script.",
        "testStrategy": "Test the refined cafe scraper by running it for a specific region and verifying the accuracy of the extracted addresses and URLs. Validate the data pipeline by feeding it sample data (including duplicates) and confirming correct insertion and deduplication in the PostgreSQL database. Test the new theme scraper against several different cafe websites to ensure it correctly parses theme details. Finally, test the scheduler by setting a short interval and confirming the end-to-end process executes automatically and successfully.",
        "subtasks": [
          {
            "id": 1,
            "title": "Refine Naver Map Cafe Scraper",
            "description": "Enhance the existing `scrape_naver_map_cafes` function in `scraping.py` to extract comprehensive cafe details, including address and official website URL.",
            "status": "done",
            "dependencies": [],
            "details": "Modify the Selenium-based function to parse the Naver Map details panel for each discovered escape room cafe. The function should extract the cafe's name, full address, and the URL to its official website. This data will be the foundation for subsequent steps.",
            "testStrategy": "Run the script targeting a specific, limited geographical area (e.g., 'Hongdae'). Manually cross-reference the output for 10-15 cafes with Naver Maps to ensure the extracted addresses and website URLs are accurate."
          },
          {
            "id": 2,
            "title": "Implement PostgreSQL Pipeline for Cafe Data",
            "description": "Develop a data pipeline to process, clean, and store the scraped cafe information into the PostgreSQL database, including deduplication logic.",
            "status": "done",
            "dependencies": [
              1
            ],
            "details": "Create a function or class that takes the list of scraped cafes. This pipeline will connect to the PostgreSQL database, clean the data (e.g., standardize address formats), and check for existing entries (based on name and address) to prevent duplicates before inserting new records into the `cafes` table.",
            "testStrategy": "Provide a test list of cafe data, including several duplicates and entries with extra whitespace, to the pipeline. Use a database client to verify that only unique, cleaned records are inserted into the `cafes` table."
          },
          {
            "id": 3,
            "title": "Develop Theme Scraper for Official Websites",
            "description": "Create a new function to scrape theme details (name, genre, difficulty) from the official cafe websites collected in the first step.",
            "status": "done",
            "dependencies": [
              1
            ],
            "details": "Implement a new Selenium-based function, e.g., `scrape_theme_details(url)`, that navigates to a cafe's website. It should locate the 'themes' or 'games' section and parse the page to extract details for each theme. The implementation should be flexible enough to handle variations in website layouts.",
            "testStrategy": "Test the function against 3-5 different official cafe websites with varying structures. Verify that it correctly extracts all available theme information and handles cases where a theme page or specific details are missing without errors."
          },
          {
            "id": 4,
            "title": "Integrate Theme Data into PostgreSQL Pipeline",
            "description": "Extend the data pipeline to handle and store scraped theme information, linking it to the corresponding cafes in the database.",
            "status": "done",
            "dependencies": [
              2,
              3
            ],
            "details": "Modify the main script to orchestrate the process. After a cafe is processed by the pipeline (inserted or found), its database ID should be retrieved. The theme scraper will then be called with the cafe's website URL, and the resulting theme data will be inserted into the `themes` table with the correct `cafe_id` as a foreign key.",
            "testStrategy": "Run the end-to-end scraping and storage process for a single cafe that has multiple themes. Connect to the database and verify that the cafe exists in the `cafes` table and that all its themes are correctly listed in the `themes` table with the proper `cafe_id`."
          },
          {
            "id": 5,
            "title": "Automate Scraping with a Weekly Scheduler",
            "description": "Use `APScheduler` in `scheduler.py` to automate the execution of the entire scraping and storage process on a weekly basis.",
            "status": "done",
            "dependencies": [
              4
            ],
            "details": "Create a `scheduler.py` script that imports and configures `APScheduler`. Define a job that calls the main function of the scraping script. Schedule this job to run weekly. Implement logging to record the start time, end time, and success or failure of each scheduled run.",
            "testStrategy": "For testing, configure the scheduler to run every 5 minutes. Activate the scheduler and monitor the logs and database to confirm that the entire scraping and storage process is triggered automatically and completes as expected."
          }
        ]
      },
      {
        "id": 13,
        "title": "Backend: Core API Endpoints for Cafes and Themes",
        "description": "Develop the core RESTful API endpoints required to serve cafe and theme data to the frontend, including search and filtering capabilities.",
        "details": "Using FastAPI, implement the following endpoints: `GET /cafes` with query parameters for filtering by region and name. `GET /cafes/{id}` to fetch details for a single cafe. `GET /themes` with query parameters for filtering by genre, difficulty, recommended players, and rating. `GET /themes/{id}` for specific theme details. `GET /themes/{id}/reviews` to list reviews for a theme. Implement efficient database queries to handle filtering and ensure response times are under 1 second.",
        "testStrategy": "Use Swagger UI (auto-generated by FastAPI) or Postman to test each endpoint with various valid and invalid parameters. Write unit tests for the business logic of each endpoint and integration tests to verify the database interactions. Performance test the endpoints with a large dataset to ensure they meet the 1-second response time requirement.",
        "priority": "high",
        "dependencies": [
          11,
          12
        ],
        "status": "in-progress",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Frontend: Main Page UI and Content Sections",
        "description": "Build the main page of the web application, featuring a central search bar, curated content sections, and quick navigation links.",
        "details": "Using React, create a `MainPage` component. Implement a prominent `SearchBar` component. Create reusable `ContentSection` components for '인기 테마 TOP 10', '이번 주 신규 테마', and '지역별 추천 카페'. These sections will initially fetch data from the backend API. Add styled buttons or links for major regions like '홍대', '강남', '건대'. Ensure the page layout is responsive and adheres to a mobile-first design approach.",
        "testStrategy": "Visually inspect the main page on various screen sizes (desktop, tablet, mobile) to ensure responsiveness. Use React Testing Library to test that all components render correctly. Verify that the content sections successfully fetch and display data from the backend APIs. Mock API calls in tests to isolate frontend component logic.",
        "priority": "medium",
        "dependencies": [
          13
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Frontend: Search and Filtering Functionality",
        "description": "Implement the search and filtering page, allowing users to find cafes and themes based on various criteria and view results in both list and map formats.",
        "details": "Create a `SearchPage` component in React. Implement filter controls: multi-select dropdowns for region and genre, a slider/button group for difficulty and rating, and buttons for recommended players. Manage the state of these filters using React hooks (`useState`, `useEffect`). When filters are applied, make an API call to `GET /themes` or `GET /cafes` with the appropriate query parameters. Implement a toggle to switch between a `ListView` component and a `MapView` component to display the results.",
        "testStrategy": "Test the filter controls individually and in combination to ensure the correct API requests are generated. Verify that the application state updates correctly as filters are changed. Use React Testing Library to simulate user interactions with the filter controls and assert that the correct data is fetched and displayed.",
        "priority": "high",
        "dependencies": [
          13
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Frontend: Map View for Search Results",
        "description": "Develop the map view for search results, displaying cafe locations as pins on a map and providing summary information.",
        "details": "Integrate a mapping library like `react-kakao-maps-sdk` or a similar library for Naver Maps. The `MapView` component will receive the filtered list of cafes as a prop. For each cafe, render a pin on the map at its `latitude` and `longitude`. Implement an `onClick` event for each pin to show an infowindow containing the cafe's name and rating. The infowindow should have a link that navigates the user to the cafe's detail page.",
        "testStrategy": "Verify that pins are correctly rendered on the map for a given set of search results. Test the click functionality on pins to ensure the infowindow appears with the correct information. Click the link in the infowindow and confirm it navigates to the correct detail page URL. Test with zero results to ensure the map displays gracefully.",
        "priority": "medium",
        "dependencies": [
          15
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Frontend: Cafe and Theme Detail Pages",
        "description": "Create the detailed information pages for both escape room cafes and individual themes, including all relevant information and user reviews.",
        "details": "Create dynamic route pages in React, e.g., `/cafes/[id]` and `/themes/[id]`. The `CafeDetailPage` will fetch data from `GET /cafes/{id}` and display the cafe's address (with an embedded map), contact info, and a list of its themes. The `ThemeDetailPage` will fetch from `GET /themes/{id}` and display the poster, story, genre, difficulty, etc. It will also include a `ReviewList` component that fetches and displays reviews from `GET /themes/{id}/reviews`.",
        "testStrategy": "Test that navigating to a specific cafe or theme URL fetches and displays the correct data. Verify all fields from the PRD are present on the page. Check that the embedded map on the cafe page shows the correct location. Ensure the review list populates correctly. Test with invalid IDs to confirm proper error handling (e.g., showing a 'Not Found' page).",
        "priority": "medium",
        "dependencies": [
          13
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 18,
        "title": "Full Stack: User Authentication and Review Submission",
        "description": "Implement user authentication and the ability for logged-in users to post reviews on theme detail pages.",
        "details": "Backend: Extend the `users` table schema. Implement user registration and login endpoints using JWT for authentication. Create the `POST /themes/{id}/reviews` endpoint, protecting it with an authentication middleware that requires a valid JWT. Frontend: Create login and registration pages/modals. Implement global state management (e.g., React Context or Zustand) to store user authentication status. On the `ThemeDetailPage`, show a 'Write a Review' form (with star rating and a comment box) only to logged-in users. On form submission, send an authenticated POST request to the backend.",
        "testStrategy": "Backend: Test registration and login endpoints. Test that the review posting endpoint returns a 401/403 error without a valid token and a 201 success with a valid token. Frontend: Test the login/logout flow. Verify that the review form is only visible to authenticated users. Submit a review and confirm that it appears in the review list after a successful post.",
        "priority": "medium",
        "dependencies": [
          17
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 19,
        "title": "Admin Panel for Data Management",
        "description": "Create a secure web-based admin panel for internal use to manage and manually correct the data collected by the scraper.",
        "details": "Build a simple, separate frontend application (or a protected section of the main app) for the admin panel. It should provide CRUD (Create, Read, Update, Delete) interfaces for the `cafes` and `themes` tables. Implement secure login for administrators. This panel will allow staff to fix incorrect data, remove closed cafes, or manually add new themes that the scraper might have missed. The backend will need corresponding protected API endpoints (e.g., `PUT /cafes/{id}`, `DELETE /themes/{id}`) accessible only to admin users.",
        "testStrategy": "Test that only users with admin privileges can access the admin panel and its API endpoints. Perform CRUD operations on cafes and themes and verify the changes are reflected in the main database and on the public-facing website. Test data validation on the admin forms.",
        "priority": "low",
        "dependencies": [
          11
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 20,
        "title": "CI/CD Pipeline and Production Deployment",
        "description": "Configure and automate the deployment process for the frontend, backend, and database, and schedule the recurring data scraping job.",
        "details": "Frontend: Set up a CI/CD pipeline to deploy the React application to Vercel on every push to the main branch. Backend: Containerize the FastAPI application using Docker. Deploy the container to a cloud service like AWS ECS or Google Cloud Run. Database: Provision a managed PostgreSQL instance on AWS RDS or a similar service. Scraper: Configure the scraping script to run on a schedule using a service like AWS Lambda with EventBridge triggers or a cron job on a dedicated EC2 instance.",
        "testStrategy": "Trigger a deployment and verify that the new version of the frontend and backend are live. Check that the application connects successfully to the production database. Manually trigger the scheduled scraping job and confirm it runs successfully in the production environment. Monitor service health and logs to ensure stability and meet the 99.5% uptime requirement.",
        "priority": "medium",
        "dependencies": [
          14,
          18,
          19
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-18T10:34:46.302Z",
      "updated": "2025-07-19T09:46:26.980Z",
      "description": "Tasks for master context"
    }
  }
}